{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ff4b0e",
   "metadata": {},
   "source": [
    "# Read Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f8c9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe11ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCE_DIR = \"Resources\"\n",
    "HARRY_POTTER_SS_FILE = \"Harry_Potter_and_Sorcerer's_Stone.txt\"\n",
    "FILE_PATH = os.path.join(RESOURCE_DIR, HARRY_POTTER_SS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4058c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_PATH, 'r', encoding='windows-1252') as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea34427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 500 characters of the book:\n",
      "\n",
      "Harry Potter and the Sorcerer's Stone \n",
      "\n",
      "CHAPTER ONE \n",
      "\n",
      "THE BOY WHO LIVED \n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. \n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large musta\n"
     ]
    }
   ],
   "source": [
    "print(f\"First 500 characters of the book:\\n\\n{raw_text[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d680df",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c5a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a29447",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2115f4",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8953495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "522504ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, raw_text, tokenizer, context_size, stride):\n",
    "        self.input_token_ids = []\n",
    "        self.target_token_ids = []\n",
    "\n",
    "        all_token_ids = tokenizer.encode(raw_text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0, len(all_token_ids) - context_size, stride):\n",
    "            input_chunk = all_token_ids[i : i + context_size]\n",
    "            target_chunk = all_token_ids[i + 1 : i + context_size + 1]\n",
    "            self.input_token_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_token_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_token_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.input_token_ids[idx]\n",
    "        y = self.target_token_ids[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c97fd",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f6e2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd08da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(raw_text, tokenizer, context_size=256, stride=256, batch_size=8,\n",
    "                         shuffle=True, num_workers=0, drop_last=True):\n",
    "    \n",
    "    dataset = GPTDatasetV1(raw_text, tokenizer, context_size, stride)\n",
    "    \n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, num_workers=num_workers, drop_last=drop_last)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58dad9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 4\n",
    "CONTEXT_SIZE = MAX_LENGTH\n",
    "STRIDE = MAX_LENGTH\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "194be915",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = create_dataloader_v1(raw_text, tokenizer, context_size=CONTEXT_SIZE,\n",
    "                                   stride=STRIDE, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "670d7b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token IDs shape: torch.Size([8, 4])\n",
      "\n",
      "Input token IDs:\n",
      "tensor([[18308, 14179,   290,   262],\n",
      "        [30467,   338,  8026,   220],\n",
      "        [  198,   198, 41481, 16329],\n",
      "        [  220,   198,   198, 10970],\n",
      "        [16494,    56, 19494,   406],\n",
      "        [ 3824,  1961,   220,   198],\n",
      "        [  198,  5246,    13,   290],\n",
      "        [ 9074,    13,   360,  1834]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iter = iter(data_loader)\n",
    "\n",
    "input_token_ids, target_token_ids = next(iter)\n",
    "\n",
    "print(f\"Input token IDs shape: {input_token_ids.shape}\\n\")\n",
    "\n",
    "print(f\"Input token IDs:\\n{input_token_ids}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db059605",
   "metadata": {},
   "source": [
    "# Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "263c8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 50257  # GPT-2 vocabulary size\n",
    "EMBEDDING_DIM = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4173e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddingg_layer = torch.nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "780daf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token embeddings shape: torch.Size([8, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "input_token_embedding = token_embeddingg_layer(input_token_ids)\n",
    "\n",
    "print(f\"Input token embeddings shape: {input_token_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6e738fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-4.9818e-01, -4.6472e-01,  3.9764e-01,  ...,  7.9246e-01,\n",
      "           1.1571e+00,  5.3370e-01],\n",
      "         [ 2.2044e+00,  2.2840e-01,  1.6137e+00,  ..., -7.6135e-01,\n",
      "           2.2072e-03,  1.8693e+00],\n",
      "         [-7.9827e-01, -5.4600e-02,  9.6870e-01,  ..., -1.5319e+00,\n",
      "          -2.2185e+00, -1.5200e+00],\n",
      "         [-2.4486e-01,  2.7383e-01, -1.1582e+00,  ..., -1.5464e+00,\n",
      "          -1.1343e+00,  5.9144e-01]],\n",
      "\n",
      "        [[-1.2179e-01,  4.7988e-01, -9.8560e-01,  ..., -8.1018e-02,\n",
      "          -1.0450e+00, -1.1603e+00],\n",
      "         [-3.6685e-02, -1.3806e-01, -1.1217e+00,  ..., -4.6414e-01,\n",
      "           6.6517e-01, -1.8198e-01],\n",
      "         [-1.8753e+00,  9.9881e-01,  4.3583e-01,  ..., -8.4714e-01,\n",
      "          -4.8133e-01,  9.1154e-01],\n",
      "         [ 6.2563e-01,  1.0582e+00, -1.1504e-01,  ..., -6.9983e-01,\n",
      "          -7.9212e-01,  6.8030e-01]],\n",
      "\n",
      "        [[ 1.2907e-01, -4.0606e-01,  5.1460e-01,  ...,  4.4782e-01,\n",
      "          -5.3980e-01, -4.0373e-01],\n",
      "         [ 1.2907e-01, -4.0606e-01,  5.1460e-01,  ...,  4.4782e-01,\n",
      "          -5.3980e-01, -4.0373e-01],\n",
      "         [ 5.1179e-01, -9.3633e-01,  1.5339e-01,  ...,  1.2069e+00,\n",
      "          -5.2135e-01,  2.3283e-02],\n",
      "         [ 8.9233e-01, -8.6106e-02, -1.0490e+00,  ..., -1.0284e+00,\n",
      "           9.8452e-01, -3.2356e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2671e+00, -1.4384e+00, -5.6252e-01,  ..., -1.4466e-01,\n",
      "           1.0937e+00, -1.0112e+00],\n",
      "         [-6.9077e-01, -5.6628e-01,  1.3949e-01,  ...,  8.7633e-01,\n",
      "           1.0178e+00,  3.5611e-01],\n",
      "         [ 6.2563e-01,  1.0582e+00, -1.1504e-01,  ..., -6.9983e-01,\n",
      "          -7.9212e-01,  6.8030e-01],\n",
      "         [ 1.2907e-01, -4.0606e-01,  5.1460e-01,  ...,  4.4782e-01,\n",
      "          -5.3980e-01, -4.0373e-01]],\n",
      "\n",
      "        [[ 1.2907e-01, -4.0606e-01,  5.1460e-01,  ...,  4.4782e-01,\n",
      "          -5.3980e-01, -4.0373e-01],\n",
      "         [-1.3691e+00, -1.6405e+00,  9.7783e-01,  ...,  4.9113e-01,\n",
      "           1.1479e+00, -8.9824e-01],\n",
      "         [ 3.2545e-02,  1.3818e+00, -4.6962e-01,  ..., -8.1328e-01,\n",
      "          -1.7823e+00, -5.1137e-01],\n",
      "         [-7.9827e-01, -5.4600e-02,  9.6870e-01,  ..., -1.5319e+00,\n",
      "          -2.2185e+00, -1.5200e+00]],\n",
      "\n",
      "        [[ 4.7437e-01, -4.6169e-01, -1.0745e+00,  ..., -3.0458e-01,\n",
      "          -3.0090e-01, -1.3591e-01],\n",
      "         [ 3.2545e-02,  1.3818e+00, -4.6962e-01,  ..., -8.1328e-01,\n",
      "          -1.7823e+00, -5.1137e-01],\n",
      "         [-2.0351e+00,  1.0202e+00, -6.9954e-01,  ...,  5.9132e-01,\n",
      "          -1.5450e+00,  1.0071e+00],\n",
      "         [-9.9278e-01, -6.6006e-01,  3.7416e-01,  ..., -3.8289e-01,\n",
      "          -1.6054e-01, -1.9600e-01]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(input_token_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6900b8f",
   "metadata": {},
   "source": [
    "# Position Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f967706",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embedding_layer = torch.nn.Embedding(num_embeddings=CONTEXT_SIZE, embedding_dim=EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b89c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position embeddings shape: torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "pos_embedding = position_embedding_layer(torch.arange(CONTEXT_SIZE))\n",
    "\n",
    "print(f\"Position embeddings shape: {pos_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67a02654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3439,  0.8972,  0.4373,  ..., -1.1304, -0.4956, -0.3342],\n",
      "        [ 0.3613,  2.0763,  1.6107,  ..., -0.7132,  0.1108,  0.8191],\n",
      "        [-0.0317,  0.3340,  0.1873,  ..., -0.4138,  2.2604, -2.4380],\n",
      "        [ 2.0926, -0.4425, -0.5229,  ...,  1.0921, -0.6074, -0.7991]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pos_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57daa9",
   "metadata": {},
   "source": [
    "# Input Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5f969",
   "metadata": {},
   "source": [
    "**Input Embedding = Vector Embedding + Position Embeddingg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc1dd656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input embeddings after adding position embeddings shape: torch.Size([8, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = input_token_embedding + pos_embedding # Broadcasting happens here\n",
    "\n",
    "print(f\"Input embeddings after adding position embeddings shape: {input_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8416b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5433e-01,  4.3246e-01,  8.3499e-01,  ..., -3.3799e-01,\n",
      "           6.6150e-01,  1.9951e-01],\n",
      "         [ 2.5657e+00,  2.3047e+00,  3.2244e+00,  ..., -1.4745e+00,\n",
      "           1.1302e-01,  2.6885e+00],\n",
      "         [-8.3002e-01,  2.7938e-01,  1.1560e+00,  ..., -1.9457e+00,\n",
      "           4.1915e-02, -3.9580e+00],\n",
      "         [ 1.8478e+00, -1.6865e-01, -1.6810e+00,  ..., -4.5438e-01,\n",
      "          -1.7417e+00, -2.0771e-01]],\n",
      "\n",
      "        [[ 2.2207e-01,  1.3771e+00, -5.4825e-01,  ..., -1.2115e+00,\n",
      "          -1.5406e+00, -1.4945e+00],\n",
      "         [ 3.2461e-01,  1.9382e+00,  4.8895e-01,  ..., -1.1773e+00,\n",
      "           7.7599e-01,  6.3715e-01],\n",
      "         [-1.9070e+00,  1.3328e+00,  6.2315e-01,  ..., -1.2609e+00,\n",
      "           1.7791e+00, -1.5264e+00],\n",
      "         [ 2.7182e+00,  6.1571e-01, -6.3791e-01,  ...,  3.9223e-01,\n",
      "          -1.3995e+00, -1.1885e-01]],\n",
      "\n",
      "        [[ 4.7293e-01,  4.9112e-01,  9.5195e-01,  ..., -6.8263e-01,\n",
      "          -1.0354e+00, -7.3791e-01],\n",
      "         [ 4.9037e-01,  1.6702e+00,  2.1253e+00,  ..., -2.6533e-01,\n",
      "          -4.2898e-01,  4.1540e-01],\n",
      "         [ 4.8004e-01, -6.0235e-01,  3.4071e-01,  ...,  7.9307e-01,\n",
      "           1.7391e+00, -2.4147e+00],\n",
      "         [ 2.9849e+00, -5.2858e-01, -1.5719e+00,  ...,  6.3650e-02,\n",
      "           3.7712e-01, -1.1227e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.2321e-01, -5.4125e-01, -1.2517e-01,  ..., -1.2751e+00,\n",
      "           5.9817e-01, -1.3454e+00],\n",
      "         [-3.2947e-01,  1.5100e+00,  1.7502e+00,  ...,  1.6318e-01,\n",
      "           1.1286e+00,  1.1752e+00],\n",
      "         [ 5.9388e-01,  1.3922e+00,  7.2272e-02,  ..., -1.1136e+00,\n",
      "           1.4683e+00, -1.7577e+00],\n",
      "         [ 2.2217e+00, -8.4854e-01, -8.2597e-03,  ...,  1.5399e+00,\n",
      "          -1.1472e+00, -1.2029e+00]],\n",
      "\n",
      "        [[ 4.7293e-01,  4.9112e-01,  9.5195e-01,  ..., -6.8263e-01,\n",
      "          -1.0354e+00, -7.3791e-01],\n",
      "         [-1.0078e+00,  4.3573e-01,  2.5885e+00,  ..., -2.2202e-01,\n",
      "           1.2587e+00, -7.9117e-02],\n",
      "         [ 7.9739e-04,  1.7158e+00, -2.8230e-01,  ..., -1.2271e+00,\n",
      "           4.7819e-01, -2.9494e+00],\n",
      "         [ 1.2943e+00, -4.9708e-01,  4.4583e-01,  ..., -4.3981e-01,\n",
      "          -2.8259e+00, -2.3191e+00]],\n",
      "\n",
      "        [[ 8.1823e-01,  4.3549e-01, -6.3716e-01,  ..., -1.4350e+00,\n",
      "          -7.9648e-01, -4.7010e-01],\n",
      "         [ 3.9384e-01,  3.4581e+00,  1.1411e+00,  ..., -1.5264e+00,\n",
      "          -1.6714e+00,  3.0775e-01],\n",
      "         [-2.0669e+00,  1.3542e+00, -5.1222e-01,  ...,  1.7751e-01,\n",
      "           7.1548e-01, -1.4308e+00],\n",
      "         [ 1.0998e+00, -1.1025e+00, -1.4871e-01,  ...,  7.0917e-01,\n",
      "          -7.6794e-01, -9.9514e-01]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(input_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
